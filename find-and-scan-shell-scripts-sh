#!/bin/bash -x
# find-and-scan-shell-scripts-sh
# Written in bash version 5.1 on Fedora 37


###  SECTION A  ###

# Implementation-dependent arguments for options parsable by `shellcheck`:
severity='error'
shells='(sh|bash|dash|ksh)'

# Environment variables
PATH="$( /usr/bin/command -p getconf PATH ):/usr/bin:/usr/sbin:${PATH}"
LC_ALL=C.UTF-8
LC_COLLATE=C

# Use `sudo`

  date

if ! sudo -v; then
  printf '\n\tValidation failed of user\x27s \x60sudo\x60 timestamp; ' 
  printf 'exiting.\n\n' 
  exit 1
fi

# Process lock
random="$RANDOM"
lock_d="${XDG_RUNTIME_DIR:-"${HOME:-/tmp}"}/.${$}.${random}.lock"
trap '
  if [[ -d "$lock_d" ]] && 
    [[ ! -L "$lock_d" ]]; 
  then 
    rm -rf -- "$lock_d"; 
  fi; 
  trap - EXIT TERM INT; 
  kill -s INT "$$"
  ' EXIT TERM INT # for cleaner xtrace output, put on one line 
if ! mkdir "$lock_d" 2> /dev/null; then
  {
    printf '\n\tCannot acquire process lock: <%s>.\n' "$lock_d"
    printf '\tID: %s\n' "$( whoami )"
    printf 'Exiting.\n\n' 
  } 1>&2
  exit 2
fi

# User variables
fstype_regexp='(autofs|binfmt_misc|bpf|cgroup2|configfs|debugfs|devpts|devtmpfs|efivarfs|fusectl|fuse.portal|hugetlbfs|iso9660|mqueue|proc|pstore|rpc_pipefs|securityfs|selinuxfs|sysfs|tmpfs|tracefs)'
timedate="$( builtin printf '%(%F_%H%M%S)T' )"
export \
  all_files \
  all_files_sorted \
  all_other_files \
  endian_wtf \
  files_from_outside_rpm \
  files_with_hashbang_comments \
  non_rpm_system_files \
  non_rpm_user_files \
  shell_scripts # arrays
export \
  count \
  datadir \
  datafile \
  d_1 \
  file \
  first_two_chars \
  fstype_regexp \
  i_{0..9} \
  LC_ALL \
  line_1 \
  mountpoint \
  n_{0..9} \
  od_o{0,1} \
  PATH \
  previous_timedirs \
  read_var \
  relevant_search_dirs \
  severity \
  shells \
  timedate \
  timedir # vars

# Functions
_age_file(){
  [[ -f "$1" ]] ||
    return 1
  local previous_aged_files new_hash
  local -A paf_hashes
  previous_aged_files=( "${1}"*[0-9] )
  declare -p previous_aged_files

  for paf in "${previous_aged_files[@]}"; do 
    if [[ -f "$paf" ]]; then
      paf_hashes["$( md5sum "$paf" | cut -d ' ' -f1 )"]="$paf" 
      new_hash="$( md5sum "$1"  | cut -d ' ' -f1 )"
      [[ -n "${paf_hashes["$new_hash"]}" ]] && 
        return 0
    fi
  done

  local old_mtime
  old_mtime="$( stat -c%Y "$1" )"
  mv "${1}" "${1}.${old_mtime}" ||
    _erx _age_file "$1";
}
_bak(){ 
  [[ "$#" -eq 0 ]] &&
    return 1
  local i_4
  for i_4 in "$@"; do 
    if [[ ! -f "${i_4}" ]]; then 
      : "File <${i_4}>> DNE"
      continue
    else 
      : 'File exists'
    fi
    
    #md5sum "$i_4" ||
      #_erx _bak $LINENO "$i_4"
    #cat "$i_4" |
      tee --output-error='exit' "${i_4}.bak" < "$i_4" > /dev/null 2>&1 ||
        _erx _bak "$i_4"
    #md5sum "${i_4}.bak" ||
      #_erx _bak $LINENO "$i_4"
  done
}
_create_datafile(){
  # Open a timestamped file & append into it the list of filenames and 
  # their crashbangs. 
    # <>
    set -x

  # datafiles
  data=( "${datafile:=crunchbangs}" /tmp/"${datafile##*/}" )
  
  # if any data files already exist, keep them
  for i_6 in "${data[@]}"; do
    if [[ -f "$i_6" ]] && [[ ! -L "$i_6" ]]; then
      mv "$i_6" "${i_6}.${$}.${random}" ||
        _erx "$LINENO"
    fi
  done
  wait -f

  # create the original datafile
  touch "${data[@]}"
  wait -f

  # header
  printf '# crunchbangs -- %s \n' "$timedate" | 
    tee --output-error='exit' "${data[@]}" ||
      _erx "${LINENO}"
  
  # content
  printf '%s\n' "${shell_scripts[@]}" |
    tee --append --output-error='exit' "${data[@]}" \
        > /dev/null 2>&1 ||
      _erx "${LINENO}"
  _bak "${data[@]}"
}
_erx(){ 
  local ec="$?"
  echo -e Error: "$@" 
  exit "$ec"
}
_num(){ 
  local i_7
  for i_7 in "$@"; do
    local -n array="$i_7" 
    echo "${#array[@]}"
  done
}
_scan_local_disks(){
  # Sort out the scripts, ie, any file beginning with a crashbang ('#!'), 
  # from the rest of the files.
  #   Note: this function can take 30-90 minutes!
  for i_1 in "${!all_files_sorted[@]}"; do

    printf '%d of %d files\r' "$i_1" "$count"
    unset file read_var od_o{0,1} line_1 
    
      #exit 101

    file="${all_files_sorted[${i_1}]}"

    ## file must exist
    #if [[ ! -e "$file" ]]; then
      #set -x
      #unset 'all_files_sorted[$i_1]'
      #continue
      #set -
    #fi

    # Bug, inordinately long interpreter paths are rare, but do occur.
    # Read from disk in binary the first two bytes of each file in 
    # the list and output it in hexadecimal.
    #   Note: `od` command is POSIX compliant
    wait -f
    builtin read -r read_var od_o0 od_o1 read_var < <( 
      sudo od -j 0 -N 2 -t x1z -v "$file" || 
        _erx "$LINENO" "$i_1" "$file" )
    unset read_var
    
    # If 'od_o' contains some non-zero data, as it should, 
    if [[ -z "$od_o0" ]]; then
      _erx "$LINENO" "$i_1" "$file";

    # compare the hexidecimal representations to find any crashbangs.
    elif [[ "${od_o0}${od_o1}" == @(2321|2123) ]]; then

      # Issue: a big endian file format, possibly DB file? not very likely.
      if [[ "${od_o0}${od_o1}" == '2123' ]]; then
        file -pk "$file" | tee -a "${timedir}/file_out"
        stat -t "$file" | tee -a "${timedir}/stat_out"
        endian_wtf+=( [$i_1]="$file" )
        unset 'all_files_sorted[$i_1]'

      # BUG: expect non-printable characters

      # Crunchbang found. Use 'read', and hope there won't be any non-printable characters.
      else
        IFS= builtin read -r line_1 < "$file" ||
          _erx "$LINENO" "$i_1" "$file";

        # Issue: the files with '#!comment' as the initial bytes. 
        # These aren't scripts, so restart the loop.
        if [[ "$line_1" =~ ^'#!comment' ]]; then
          file -pk "$file" | tee -a "${timedir}/file_out"
          stat -t "$file" | tee -a "${timedir}/stat_out"
          files_with_hashbang_comments+=( [${i_1}]="$file" )
          unset 'all_files_sorted[$i_1]'
          continue
        fi

        # Issue: crashbang files which originate outside of the rpm 
        # package manager
        if ! rpm -qf "$file" 2> /dev/null 1>&2; then

          # user and system files from outside `rpm`

          if [[ "$file" = /@(root|home|run/media)/* ]]; then
            file -pk "$file" | tee -a "${timedir}/file_out"
            stat -t "$file" | tee -a "${timedir}/stat_out"
            non_rpm_user_files+=( [${i_1}]="$file" )
            unset 'all_files_sorted[$i_1]'
            continue

          else
            file -pk "$file" | tee -a "${timedir}/file_out"
            stat -t "$file" | tee -a "${timedir}/stat_out"
            non_rpm_system_files+=( [${i_1}]="$file" )
            unset 'all_files_sorted[$i_1]'
            continue
          fi
        fi
      fi

      # Make a record in RAM of the relevant filenames and their crashbangs.
      file -pk "$file" | tee -a "${timedir}/file_out"
      stat -t "$file" | tee -a "${timedir}/stat_out"
      shell_scripts+=( [$i_1]="$( \
        printf '%-50s   %% %% %% %%   %s\n' "$line_1" "$file" )" )
      unset 'all_files_sorted[$i_1]'

    else
      file -pk "$file" | tee -a "${timedir}/file_out"
      stat -t "$file" | tee -a "${timedir}/stat_out"
      all_other_files+=( [$i_1]="$file" )
      unset 'all_files_sorted[$i_1]'
    fi
  done
}
_usage(){
  # Usage:  _usage [exit-code]
  cat <<-\EOF
    SCF - Shell Check Find, version 1.0 (redhat-linux)
    Find and scan shell scripts depending on severity level. 
        Usage:  ./find-and-scan-shell-scripts-sh [-ehiw]
                -e error          -i info
                -h help           -w warning
    Only the first option is processed.
EOF
  exit "${1}"
}
_write_arrays(){
  # Usage: _write_arrays [one target-dir] [arrays]
  # Default directory is "$timedir".
    # <>
    #set -x

  local d_1
  : 'is function-pos-parm number 1 a directory?'
  if [[ -d "$1" ]]; then
    d_1="$1"
    shift
  fi

  for i_8 in "$@"; do 
    local target_f
          target_f="${d_1:-"${timedir}"}/a_${i_8}"
    # Note: `tee` without '-a' will overwrite an existing file
    declare -p "$i_8" | 
      tee --output-error='exit' "$target_f" > /dev/null 2>&1 ||
        _erx "_write_arrays $d_1 $i_8"
      [[ -f "$target_f" ]] ||
        _erx $LINENO: "$target_f"
    _bak "$target_f"
    unset -v target_f
  done
}
# Usage: _write_vars [section] [raw variable names]
_write_vars(){
  local section target_f
        section="$1"
        target_f="${timedir}/${section}_vars"
  shift
  declare -p "$@" 2> /dev/null |
    tee --output-error='exit' "$target_f" > /dev/null 2>&1 ||
      _erx "_write_vars, section $section"
  _bak "$target_f"
}
export -f \
  _create_datafile \
  _erx \
  _num \
  _scan_local_disks \
  _usage \
  _write_arrays \
  _write_vars
  #_age_file \
  _bak \


# Option parsing
if [[ "$#" -gt 0 ]]; then
  first_two_chars="${1:0:2}"

  case "${first_two_chars}" in
    --) printf '\n\tHappy Easter!\n\n'
          exit 0;;
    -e) severity='error';;
    -i) severity='info';;
    -w) severity='warning';;
    -h) _usage 0;;
    *)  _usage 1;;
  esac
fi


# Assign varnames and paths for the data directories

# BUG? `findmnt` has a '--df' option

#   In case of large log files, programatically select a save directory, 
# attached to the local disk, where any output can be saved; prefer USB 
# flash drives. This particular `df` command will output three alpha-
# numeric strings separated by whitespace on a single line. `sort` the 
# output by descending size. With `awk`, take the device with the most 
# available space and get its mountpoint with `findmnt`. If there is no 
# output, then set 'mountpoint' according to environment variables. 
mapfile -t df_o < <( 
  sudo df --sync --local --output='fstype,avail,source' --block-size=1 | grep --extended-regexp --invert-match '^Type[[:space:]]*Avail' | grep --extended-regexp --invert-match -e ^"$fstype_regexp" -e 'live-rw'$ | sort --general-numeric-sort --reverse --key=2 )
export df_o

  declare -p df_o
  #exit 111

read -r fstype read_var device < <( 
  printf '%s\n' "${df_o[@]}" | head -n 1 )
unset read_var

  declare -p fstype device

mountpoint="$( 
  findmnt --canonicalize --output=target --noheadings "$device" )"

  #exit 112

# BUG: needs a test for whether or not there are any unmounted USB drives. 
# automatically using '/' as mountpoint is, in this case, ie, on a live usb,
# not so good of an idea.

[[ -z "${mountpoint}" ]] &&
  mountpoint="${lock_d:-"${TMPDIR:-/tmp}"}"
scriptdir="${mountpoint}/scf.d"
datadir="${scriptdir}/latest_data"
metadir="${scriptdir}/current_meta"
timedir="${datadir}/t_${timedate}"
datafile="${timedir}/crunchbangs"
#unlisted="${timedir}/unlisted"
umask 077

  set -x


# reduce use of `sudo` in this script by setting up ACL's
case "$fstype" in
  'xfs')      :;;
  ext[2-4])   tune2fs -l "$device" | 
                grep -i 'acl'
              _erx "$LINENO" TODO;;
  *)          _erx "$LINENO" TODO;;
esac
  
# on XFS

  # <>
  sudo setfacl -R -b "${mountpoint%/*}"
  sudo setfacl -R -k "${mountpoint%/*}"

# Nearly all of the `sudo` commands below are allowing rw access, of  
# this script's datadir, so simply using ACL's will reduce the overuse 
# of `sudo`. This section takes the "$mountpoint" variable, portions
# each subdirectory name into an array index, and tests each subdi-
# rectory from the FS root up for readability by the user running
# this script (ie, a regular user). As the absolute path is recon-
# structed, when a non-readable directory is found, a recursive "r-x" 
# ACL is written, and then a recursive "rwx" is written for the 
# "$scriptdir". 
if [[ ! -r "$scriptdir" ]]; then
  mapfile -d '/' -t a <<< "${mountpoint}"; 
  export a
  a[0]='/'
  a[-1]="${a[-1]//$'\n'}"
  d=${#a[@]}; 
  for ((i=0;i<d;i++)); do 
    #printf '\n\t%d\n\n' $i; 
    #c="$b"; 
    b+="/${a[$i]}"; 
    b="$( realpath -e "$b" )"; 
    if [[ ! -r "$b" ]]; then 
      #printf '\n\tReadable:\t%s\n' "$c"; 
      #printf '\n\tUnreadable:\t%s\n' "$b"; 
      sudo setfacl -R -m "$USER":r-x "$b" || 
        break
      sudo setfacl -R -m "$USER":rwx "$scriptdir" || 
        break; 
      break
    fi ; 
  done; 
fi

  #exit 110

# make sure "$conf_d" is a directory OR create the "$conf_d" dir 
# if necessary
for conf_d in "$datadir" "$metadir"; do
  [[ -d "$conf_d" ]] ||
    mkdir --parents "$conf_d" 
done

# Label the current data as "latest."
#   Note: `find` sees dirs and symlinks as separate things 
mapfile -d '' -t previous_timedirs < <( 
  find "${datadir}" -mindepth 1 -maxdepth 1 -type d -a \! -type l \
    -name 't_*' -print0 )
export previous_timedirs

  declare -p previous_timedirs

# if "$t_dir" is empty, then delete it; otherwise `mv` it out
# of the `latest` dir
for t_dir in "${previous_timedirs[@]}"; do 
  rmdir --ignore-fail-on-non-empty "$t_dir" 
  
    test ! -e "$t_dir" &&
      : 't_dir DNE' 

  : 'of previous timedir' 
  #   Note: with `test`, dirs and symlinks can refer to the same inode
  if [[ -e "$t_dir" ]] &&
    [[ ! -L "$t_dir" ]]; 
  then
    mv "${previous_timedirs[@]}" "$scriptdir"
  else
    continue
  fi
done

: 'of current timedir'
if [[ ! -d "${timedir}" ]]; then
  mkdir "${timedir}" ||
    _erx "${LINENO}"
fi


# BUG:  Reduce Search Time  ==  RST

#   Gather filenames from local attached disk storage

# If a prior record of the relevant_search_dirs array exists, and 
# if that prior record matches the new record, then it's possible the 
# all_files list would be the same, too. So if the new relevant_\
# search_dirs list is new, then do the full all_files search again.
# But if they're the same, then ...
#

# 
array='relevant_search_dirs'
rst="${metadir}/a_${array}" 

  if [[ -f "$rst" ]]; then : ok; else : no; fi

if [[ -f "$rst" ]] &&
  [[ ! -L "$rst" ]];
then

  _age_file "${rst}".bak
  _bak "$rst"

  # get the hash of the prior array, and 
  hash_old="$( md5sum "$rst" )"

  # get the prior count of indices
  # shellcheck disable=SC1090
  source "$rst"
  array_count_old="$( _num "$array" )"
  unset "$array"

  # delete the record
  rm -f "$rst"
fi


# ...then create a new record and...
mapfile -d '' -t relevant_search_dirs < <(
  sudo find / -mindepth 1 -maxdepth 1 -type d \! -empty \
    \( \! -name proc -a \! -name sys -a \! -iname 'scf*' \) -print0 )
export relevant_search_dirs
_write_arrays "$metadir" relevant_search_dirs

if [[ -v array_count_old ]]; then 
  _age_file "${rst}".bak
  _bak "$rst"

  # get the hash of the new array, and 
  hash_new="$( md5sum "$rst" )"

  # get the new count of indices
  array_count_new="$( _num "$array" )"

  if [[ "${hash_old%% *}" != "${hash_new%% *}" ]] ||
    [[ "$array_count_old" != "$array_count_new" ]]; 
  then 
    must_find_all_files='y'
  fi
fi
  
  #exit $LINENO


# 
array='all_files'
rst="${metadir}/a_${array}" 
  
  if [[ -f "$rst" ]]; then : ok; else : na; fi

if [[ "$must_find_all_files" != 'y' ]] &&
  [[ -f "$rst" ]] &&
  [[ ! -L "$rst" ]];
then

  _age_file "${rst}".bak
  _bak "$rst"

  # WHY?
  ## get the hash of the prior array, and 
  #hash_old="$( md5sum "$rst" )"

  # WHY?
  ## get the prior count of indices
  #source "$rst"
  #array_count_old="$( _num "$array" )"
  #unset "$array"

  # get byte count of record file
  byte_count="$( wc -c "$rst" )"
  [[ "$byte_count" -lt 500 ]] && 
    must_find_all_files='y'

  
  # get delta of mtime to now
  mtime_age_in_hours=$(( $(( $( date +%s ) - \
    $( stat -c%Y "$rst" ) )) / 60 / 60 ))
  [[ "$mtime_age_in_hours" -gt 72 ]] &&
    must_find_all_files='y'

fi
  


if [[ "$must_find_all_files" != 'y' ]]; 
then

  # ...find all relevant files on disk....
  # DEBUG: "${relevant_search_dirs[@]}" OR '/usr/sbin' OR /usr/{,s}bin

    date
    relevant_search_dirs=( /usr/sbin )
    #relevant_search_dirs=( /usr/sbin /usr/bin )
    declare -p relevant_search_dirs

  mapfile -d '' -t all_files < <( 
    sudo find "${relevant_search_dirs[@]}" -type f \! -empty \
      -print0 2> /dev/null )
  export all_files
  _write_arrays "$metadir" all_files
fi

  echo 'number, all_files:' "${#all_files[@]}"
  #exit 103





# Then sort the original array with mapfile and test it.
  # <>
  set -; printf 'printf \x24array\n'

mapfile -d '' -t all_files_sorted < <(
  printf '%s\0' "${all_files[@]}" |
    sort --zero-terminated )

  # <>
  set -x; : 'set -x'
  
[[ "$( _num all_files )" -eq "$( _num all_files_sorted )" ]] ||
  _erx "${LINENO}"

  # <> ##############################################################
  _write_arrays all_files all_files_sorted
  _write_vars 'A' PATH LC_ALL severity shells fstype_regexp timedate \
    first_two_chars mountpoint datadir timedir datafile \
    previous_timedirs relevant_search_dirs n_0 n_7

  #exit 101
  #set -x





###  SECTION B  ###
# Add some brevity, and write the completed arrays to disk
count="${#all_files_sorted[@]}"
unset IFS

# BUG: this file existence test is ...wrong

# if the full list exists (of files on disk which begin with crash-
# bangs), then skip the 30-90 minute search phase.
if [[ ! -f /tmp/"${datafile##*/}" ]] || 
  [[ -L /tmp/"${datafile##*/}" ]]; 
then
  _scan_local_disks
  
    set -x

  _create_datafile

    set -

fi

  # <> ##############################################################
  _write_arrays shell_scripts files_with_hashbang_comments \
    files_from_outside_rpm all_other_files endian_wtf \
    non_rpm_system_files non_rpm_user_files 

  _write_vars 'B' file datafile i_1 od_o{0,1} X line_1 count

  exit 101
  set -x




    
###  SECTION C  ###    

# Make the data readable and useable.

# Alterations

# Alteration 2: fix the odd extra data segments in the middles of the rows. 
# Requires using 'relevant_search_dirs' in the above `find` path. ## works
ere_2='>?[[:space:]]{3,}<?/?[[:alnum:]].*>?[[:space:]]{3,}<?'
# Bug? is opt -n necc?
_test_2(){
  grep --extended-regexp --line-number "${ere_2}" "${1}" # ere_2
}
if _test_2 "$datafile"; then
  sed --in-place "s=${ere_2}=    =g" "$datafile" # ere_2
  \_test_2 "$datafile" &&
    _erx "${LINENO}"
fi
command -p cp --archive "$datafile" "${datafile}_extra-data-removed"
_bak "${datafile}_extra-data-removed"

  # <>
  ls -l "${datafile}"*
  wc "${datafile}"*
  md5sum "${datafile}.bak" "${datafile}_extra-data-removed"
  
  exit 101
  set -x


# Bug: high disk io, slow

# Alteration 3: Apply grep-style line numbers, ie, in-file indices. These 
# are necessary for section 'Extra,' however, can only be applied prior 
# to the full list having been subdivided. 
grep --extended-regexp --line-number '.' "${datafile}" > \
  "${datafile}_all-indexed"
_bak "${datafile}_all-indexed"


# CENTRAL TASK, 1 OF 2: Filter the list of crashbangs with the list 
# of shells.
#ere_3=^'[0-9]{1,7}:#! ?(/usr)?/bin/(env|(sh|bash|dash|ksh)?) *<?(/usr)?(/bin/)?(sh|bash|dash|ksh) ?>? *'
# Bug likely: ere3
ere_3=^"[0-9]{1,7}:#! ?(/usr)?/bin/(env|${shells}?) *<?(/usr)?(/bin/)?${shells} ?>? *"

grep --extended-regexp "${ere_3}" "${datafile}_all-indexed" > \
  "${datafile}_SC-scrpts-list" # ere_3
_bak "${datafile}_SC-scrpts-list"

  # <>
  ls -l "${datafile}"*
  wc "${datafile}"*
  exit 101
  set -x



# MAIN TASK, 2 of 2: with ShellCheck scan each script for errors
for i_2 in "${!shell_scripts[@]}"; do 
  script="${shell_scripts[${i_2}]}"

  # Run `shellcheck on the script and count the number of each issue's ID.
  mapfile -t careful < <( 
    shellcheck --severity "$severity" "$script" || 
      _erx "$LINENO" )
  mapfile -t errs < <( 
    grep --fixed-strings --invert-match 'shellcheck.net' \
        <<< "${careful[@]}" | 
      grep --extended-regexp --only-matching 'SC[0-9]{4}' | 
      sort --general-numeric-sort | 
      uniq --count |
      sed 's,^[[:space:]]*,,' || 
        _erx "$LINENO" )

  # Bug: formatting

  # If shellcheck found any issues, then open & append some 
  # prioritized work lists with indices
  if [[ -n "${errs[*]:0:1}" ]]; then 
		
    printf '<idx:%d>  %%  <%s>\n' "$i_2" "$script" >> \
      "${datafile}_found_scripts_with_indices"

    for each_error in "${errs[@]}"; do
      printf '%s %% <idx:%d>\n' "${each_error//$'\n'/}" "$i_2" >> \
        "${datafile}_found_errors_with_indices_unsorted"
    done
  fi
  unset errors script 'shell_scripts[$i_2]'
done

_bak "${datafile}_found_scripts_with_indices" \
  "${datafile}_found_errors_with_indices_unsorted"

exit 0

  # get `dnf history` transaction number
  #dnf_tx_number="$( dnf history | 
    #awk '$1 ~ /[0-9]+/ { print $1; exit }' )"

